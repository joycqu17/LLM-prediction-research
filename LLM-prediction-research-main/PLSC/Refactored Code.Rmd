---
title: "GSS Political Views Analysis - Refactored"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
options(repos = c(CRAN = "https://cloud.r-project.org"))
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)

library(haven)
library(dplyr)
library(tidyr)
library(ggplot2)
library(readr)
library(caret)
library(MLmetrics)
library(purrr)
```

# 1. Data Loading and Preparation

```{r load_data}
# Load GSS data
gss <- read_dta("GSS2024.dta")
cat("Original dimensions:", dim(gss), "\n")

# Clean and prepare data
gss_clean <- gss %>%
  select(polviews, age, educ, race, sex, occ10, region, marital) %>%
  filter(!polviews %in% c(8, 9), !is.na(polviews)) %>%
  mutate(
    polviews = as.integer(polviews),
    race = factor(race),
    sex = factor(sex),
    occ10 = factor(occ10),
    region = factor(region),
    marital = factor(marital)
  )

# Create reproducible sample
set.seed(123)
sample100 <- gss_clean %>%
  drop_na() %>%
  sample_n(100)

cat("Sample dimensions:", dim(sample100), "\n")
```

# 2. Helper Functions

```{r helper_functions}
# F1 score calculation functions
f1_macro <- function(true, pred) {
  true <- as.character(true)
  pred <- as.character(pred)
  f1_scores <- sapply(unique(true), function(cls) {
    MLmetrics::F1_Score(y_pred = pred == cls, y_true = true == cls)
  })
  mean(f1_scores, na.rm = TRUE)
}

f1_weighted <- function(true, pred) {
  true <- as.character(true)
  pred <- as.character(pred)
  classes <- unique(true)
  weights <- prop.table(table(true))
  f1_scores <- sapply(classes, function(cls) {
    MLmetrics::F1_Score(y_pred = pred == cls, y_true = true == cls)
  })
  sum(f1_scores * weights[names(f1_scores)], na.rm = TRUE)
}

# Calculate performance metrics
calculate_metrics <- function(y_true, y_pred) {
  tibble(
    MAE = mean(abs(y_true - y_pred)),
    MSE = mean((y_true - y_pred)^2),
    Accuracy = mean(y_true == y_pred) * 100,
    Within1 = mean(abs(y_true - y_pred) <= 1) * 100
  )
}

# Print metrics nicely
print_metrics <- function(metrics, model_name) {
  cat("\n", model_name, ":\n", sep = "")
  cat("Mean Absolute Error:", round(metrics$MAE, 3), "\n")
  cat("Mean Squared Error:", round(metrics$MSE, 3), "\n")
  cat("Exact Match Accuracy:", round(metrics$Accuracy, 1), "%\n")
  cat("Within ±1 Accuracy:", round(metrics$Within1, 1), "%\n")
}

# Map occupation codes to categories
map_occ10 <- function(code) {
  if (is.na(code)) return(NA_character_)
  if (code >= 10 & code <= 950) return("Management/Professional")
  if (code >= 1000 & code <= 1240) return("Service")
  if (code >= 1300 & code <= 1965) return("Sales/Office")
  if (code >= 2000 & code <= 3955) return("Construction/Maintenance")
  if (code >= 4000 & code <= 5940) return("Production/Transportation")
  if (code >= 5950 & code <= 9830) return("Military")
  return(NA_character_)
}

# Bucket age into groups
bucket_age <- function(a) {
  case_when(
    is.na(a) ~ NA_character_,
    a < 30 ~ "18–29",
    a >= 30 & a < 45 ~ "30–44",
    a >= 45 & a < 65 ~ "45–64",
    a >= 65 ~ "65+",
    TRUE ~ NA_character_
  )
}

# Label mapping
label_maps <- list(
  sex = c("1" = "Male", "2" = "Female"),
  race = c("1" = "White", "2" = "Black", "3" = "Other"),
  marital = c("1" = "Married", "2" = "Widowed", "3" = "Divorced", 
              "4" = "Separated", "5" = "Never married"),
  region = c("1" = "Northeast", "2" = "Midwest", "3" = "South", "4" = "West")
)

# Calculate bias by predictor
bias_by_predictor <- function(data, predictor) {
  data %>%
    group_by({{ predictor }}) %>%
    summarise(
      n = n(),
      mean_error_var = mean(error_var, na.rm = TRUE),
      mean_error_narr = mean(error_narr, na.rm = TRUE),
      prop_too_cons_var = mean(error_var > 0, na.rm = TRUE),
      prop_too_lib_var = mean(error_var < 0, na.rm = TRUE),
      prop_too_cons_narr = mean(error_narr > 0, na.rm = TRUE),
      prop_too_lib_narr = mean(error_narr < 0, na.rm = TRUE),
      .groups = "drop"
    ) %>%
    arrange(desc(mean_error_var))
}

# Plot mean error by predictor
plot_mean_error_by_predictor <- function(data, predictor) {
  pred_sym <- rlang::ensym(predictor)
  pred_name <- rlang::as_name(pred_sym)
  
  summary_df <- data %>%
    group_by(!!pred_sym) %>%
    summarise(
      n = n(),
      mean_error_var = mean(error_var, na.rm = TRUE),
      mean_error_narr = mean(error_narr, na.rm = TRUE),
      .groups = "drop"
    ) %>%
    pivot_longer(
      cols = c(mean_error_var, mean_error_narr),
      names_to = "model",
      values_to = "mean_error"
    ) %>%
    mutate(model = recode(model,
                          mean_error_var = "Variable model",
                          mean_error_narr = "Narrative model"))
  
  # Add human-readable labels
  if (pred_name == "occ10") {
    summary_df <- summary_df %>%
      mutate(predictor_label = vapply(.data[[pred_name]], map_occ10, character(1)))
  } else if (pred_name == "age") {
    summary_df <- summary_df %>%
      mutate(predictor_label = bucket_age(.data[[pred_name]]))
  } else if (pred_name == "educ") {
    summary_df <- summary_df %>%
      mutate(predictor_label = factor(as.numeric(.data[[pred_name]]),
                                      levels = sort(unique(as.numeric(.data[[pred_name]])))))
  } else if (pred_name %in% names(label_maps)) {
    map_vec <- label_maps[[pred_name]]
    summary_df <- summary_df %>%
      mutate(predictor_label = map_vec[as.character(.data[[pred_name]])])
  } else {
    summary_df <- summary_df %>%
      mutate(predictor_label = as.character(.data[[pred_name]]))
  }
  
  ggplot(summary_df, aes(x = predictor_label, y = mean_error, fill = model)) +
    geom_col(position = "dodge") +
    geom_hline(yintercept = 0, linetype = "dashed") +
    labs(title = paste("Mean signed error by", pred_name),
         x = pred_name,
         y = "Mean signed error (prediction - true)",
         fill = "Model") +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
}
```

# 3. Core Analysis Function

```{r core_analysis_function}
# Main analysis function for any classification scheme
analyze_classification <- function(sample_data, var_file, narr_file, 
                                   class_var, class_suffix, save_prefix) {
  
  cat("\n", rep("=", 60), "\n", sep = "")
  cat("ANALYSIS:", class_suffix, "\n")
  cat(rep("=", 60), "\n\n")
  
  # Load predictions
  var_pred <- read.csv(var_file)
  narr_pred <- read.csv(narr_file)
  
  # Calculate and print metrics
  y_true <- as.numeric(sample_data[[class_var]])
  
  metrics_var <- calculate_metrics(y_true, as.numeric(var_pred$pred_polview))
  print_metrics(metrics_var, "Variable Model")
  
  metrics_narr <- calculate_metrics(y_true, as.numeric(narr_pred$pred_polview_narr))
  print_metrics(metrics_narr, "Narrative Model")
  
  # Build comprehensive dataframe
  df <- sample_data %>%
    mutate(row_id = row_number()) %>%
    select(row_id, POLVIEWS_TRUE = !!sym(class_var),
           age, sex, race, educ, marital, occ10, region) %>%
    inner_join(var_pred %>% mutate(row_id = row_number()) %>%
                 select(row_id, pred_var = pred_polview), by = "row_id") %>%
    inner_join(narr_pred %>% mutate(row_id = row_number()) %>%
                 select(row_id, pred_narr = pred_polview_narr), by = "row_id") %>%
    mutate(
      POLVIEWS_TRUE_fac = factor(POLVIEWS_TRUE),
      pred_var_fac = factor(pred_var, levels = levels(POLVIEWS_TRUE_fac)),
      pred_narr_fac = factor(pred_narr, levels = levels(POLVIEWS_TRUE_fac)),
      polviews_num = as.numeric(as.character(POLVIEWS_TRUE)),
      pred_var_num = as.numeric(as.character(pred_var)),
      pred_narr_num = as.numeric(as.character(pred_narr)),
      error_var = pred_var_num - polviews_num,
      error_narr = pred_narr_num - polviews_num
    )
  
  # F1 Scores
  results <- tibble(
    Model = c("Variable Model", "Narrative Model"),
    Macro_F1 = c(f1_macro(df$POLVIEWS_TRUE_fac, df$pred_var_fac),
                 f1_macro(df$POLVIEWS_TRUE_fac, df$pred_narr_fac)),
    Weighted_F1 = c(f1_weighted(df$POLVIEWS_TRUE_fac, df$pred_var_fac),
                    f1_weighted(df$POLVIEWS_TRUE_fac, df$pred_narr_fac))
  )
  
  cat("\nF1 Scores:\n")
  print(results)
  
  # Bias analysis
  cat("\nMean Errors:\n")
  cat("Variable Model:", round(mean(df$error_var, na.rm = TRUE), 3), "\n")
  cat("Narrative Model:", round(mean(df$error_narr, na.rm = TRUE), 3), "\n")
  
  # Mislabeled cases comparison
  mislabeled <- df %>%
    mutate(
      var_wrong = pred_var != POLVIEWS_TRUE,
      narr_wrong = pred_narr != POLVIEWS_TRUE,
      case_type = case_when(
        var_wrong & !narr_wrong ~ "Only Variable Model Wrong",
        !var_wrong & narr_wrong ~ "Only Narrative Model Wrong",
        var_wrong & narr_wrong ~ "Both Wrong",
        TRUE ~ "Both Correct"
      ),
      diff_var = as.numeric(pred_var) - as.numeric(POLVIEWS_TRUE),
      diff_narr = as.numeric(pred_narr) - as.numeric(POLVIEWS_TRUE),
      bias_var = case_when(
        !var_wrong ~ "Correct",
        diff_var > 0 ~ "Too Conservative",
        diff_var < 0 ~ "Too Liberal",
        TRUE ~ NA_character_
      ),
      bias_narr = case_when(
        !narr_wrong ~ "Correct",
        diff_narr > 0 ~ "Too Conservative",
        diff_narr < 0 ~ "Too Liberal",
        TRUE ~ NA_character_
      )
    ) %>%
    select(row_id, POLVIEWS_TRUE, pred_var, pred_narr,
           var_wrong, narr_wrong, case_type, bias_var, bias_narr)
  
  write.csv(mislabeled, paste0(save_prefix, "_mislabeled_cases_comparison.csv"),
            row.names = FALSE)
  
  # Bias table
  bias_table <- mislabeled %>%
    select(bias_var, bias_narr) %>%
    pivot_longer(everything(), names_to = "model", values_to = "bias") %>%
    filter(bias != "Correct") %>%
    group_by(model, bias) %>%
    summarise(count = n(), .groups = "drop_last") %>%
    mutate(percent = count / sum(count) * 100) %>%
    ungroup() %>%
    mutate(model = recode(model,
                          bias_var = "Variable Model",
                          bias_narr = "Narrative Model")) %>%
    arrange(model, bias)
  
  cat("\nBias Distribution:\n")
  print(bias_table)
  
  # Distribution plots
  p1 <- ggplot(df, aes(x = POLVIEWS_TRUE)) +
    geom_bar() +
    ggtitle("True POLVIEWS Distribution") +
    theme_minimal()
  
  p2 <- ggplot(df, aes(x = pred_var)) +
    geom_bar() +
    ggtitle("Variable Model Pred Distribution") +
    theme_minimal()
  
  p3 <- ggplot(df, aes(x = pred_narr)) +
    geom_bar() +
    ggtitle("Narrative Model Pred Distribution") +
    theme_minimal()
  
  print(p1)
  print(p2)
  print(p3)
  
  # Bias by predictor
  df$occ10 <- as.numeric(as.character(df$occ10))
  
  cat("\nBias by Age:\n")
  print(bias_by_predictor(df, age))
  cat("\nBias by Sex:\n")
  print(bias_by_predictor(df, sex))
  cat("\nBias by Race:\n")
  print(bias_by_predictor(df, race))
  cat("\nBias by Education:\n")
  print(bias_by_predictor(df, educ))
  cat("\nBias by Marital Status:\n")
  print(bias_by_predictor(df, marital))
  cat("\nBias by Occupation:\n")
  print(bias_by_predictor(df, occ10))
  cat("\nBias by Region:\n")
  print(bias_by_predictor(df, region))
  
  # Plot error by predictors
  print(plot_mean_error_by_predictor(df, age))
  print(plot_mean_error_by_predictor(df, sex))
  print(plot_mean_error_by_predictor(df, race))
  print(plot_mean_error_by_predictor(df, educ))
  print(plot_mean_error_by_predictor(df, marital))
  print(plot_mean_error_by_predictor(df, occ10))
  print(plot_mean_error_by_predictor(df, region))
  
  return(df)
}
```

# 4. Classification Scheme Creation

```{r create_classifications}
# Original 7-point scale (already done in sample100)

# Binary classification (0 = Not conservative, 1 = Conservative)
sample100_binary <- sample100 %>%
  mutate(polviews_binary = case_when(
    polviews %in% c(1, 2, 3, 4) ~ 0,
    polviews %in% c(5, 6, 7) ~ 1
  )) %>%
  filter(!is.na(polviews_binary))

# 3-category classification (1 = Liberal, 2 = Moderate, 3 = Conservative)
sample100_3 <- sample100 %>%
  mutate(polviews_3 = case_when(
    polviews %in% c(1, 2, 3) ~ 1,
    polviews %in% c(4) ~ 2,
    polviews %in% c(5, 6, 7) ~ 3
  )) %>%
  filter(!is.na(polviews_3))

# 4-category classification
sample100_4 <- sample100 %>%
  mutate(polviews_4 = case_when(
    polviews %in% c(1, 2) ~ 1,      # Extremely liberal
    polviews %in% c(3) ~ 2,          # Slightly liberal
    polviews %in% c(4) ~ 3,          # Moderate
    polviews %in% c(5, 6, 7) ~ 4     # Conservative
  )) %>%
  filter(!is.na(polviews_4))

# 5-category classification
sample100_5 <- sample100 %>%
  mutate(polviews_5 = case_when(
    polviews %in% c(1) ~ 1,          # Extremely liberal
    polviews %in% c(2, 3) ~ 2,       # Liberal
    polviews %in% c(4) ~ 3,          # Moderate
    polviews %in% c(5, 6) ~ 4,       # Conservative
    polviews %in% c(7) ~ 5           # Extremely conservative
  )) %>%
  filter(!is.na(polviews_5))
```

# 5. Run All Analyses

```{r, results='asis'}
# 7-point scale analysis
df_7 <- analyze_classification(
  sample100,
  "gss_gpt5_var_predictions.csv",
  "gss_gpt5_narrative_predictions.csv",
  "polviews",
  "7-Point Scale",
  "7point"
)
```


```{r, results='asis'}
# Binary analysis
df_bin <- analyze_classification(
  sample100_binary,
  "gss_gpt5_var_predictions_bin.csv",
  "gss_gpt5_narrative_predictions_bin.csv",
  "polviews_binary",
  "Binary Classification",
  "binary"
)
```


```{r, results='asis'}
# 3-category analysis
df_3 <- analyze_classification(
  sample100_3,
  "gss_gpt5_var_predictions_3.csv",
  "gss_gpt5_narrative_predictions_3.csv",
  "polviews_3",
  "3-Category Classification",
  "3cat"
)
```


```{r, results='asis'}
# 4-category analysis
df_4 <- analyze_classification(
  sample100_4,
  "gss_gpt5_var_predictions_4.csv",
  "gss_gpt5_narrative_predictions_4.csv",
  "polviews_4",
  "4-Category Classification",
  "4cat"
)
```


```{r, results='asis'}
# 5-category analysis
df_5 <- analyze_classification(
  sample100_5,
  "gss_gpt5_var_predictions_5.csv",
  "gss_gpt5_narrative_predictions_5.csv",
  "polviews_5",
  "5-Category Classification",
  "5cat"
)
```

# 6. Summary Comparison

```{r summary_comparison}
# Create summary table across all classification schemes
summary_results <- tibble(
  Classification = c("7-Point", "Binary", "3-Category", "4-Category", "5-Category"),
  Var_MAE = c(
    mean(abs(df_7$error_var)),
    mean(abs(df_bin$error_var)),
    mean(abs(df_3$error_var)),
    mean(abs(df_4$error_var)),
    mean(abs(df_5$error_var))
  ),
  Narr_MAE = c(
    mean(abs(df_7$error_narr)),
    mean(abs(df_bin$error_narr)),
    mean(abs(df_3$error_narr)),
    mean(abs(df_4$error_narr)),
    mean(abs(df_5$error_narr))
  ),
  Var_Accuracy = c(
    mean(df_7$pred_var_num == df_7$polviews_num) * 100,
    mean(df_bin$pred_var_num == df_bin$polviews_num) * 100,
    mean(df_3$pred_var_num == df_3$polviews_num) * 100,
    mean(df_4$pred_var_num == df_4$polviews_num) * 100,
    mean(df_5$pred_var_num == df_5$polviews_num) * 100
  ),
  Narr_Accuracy = c(
    mean(df_7$pred_narr_num == df_7$polviews_num) * 100,
    mean(df_bin$pred_narr_num == df_bin$polviews_num) * 100,
    mean(df_3$pred_narr_num == df_3$polviews_num) * 100,
    mean(df_4$pred_narr_num == df_4$polviews_num) * 100,
    mean(df_5$pred_narr_num == df_5$polviews_num) * 100
  )
)

cat("\nSummary Across All Classification Schemes:\n")
print(summary_results, digits = 3)
```